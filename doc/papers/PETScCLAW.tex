\documentclass[12pt]{article}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{color}
\usepackage{url}
\usepackage{hyperref}

\title{PETScCLAW Plan}
\author{Matthew G. Knepley\\
\small Computation Institute\\[-0.8ex]
\small University of Chicago, Chicago, IL\\
\small \texttt{knepley@ci.uchicago.edu}\\
}

\begin{document}
\maketitle

\section{Software Strategy}

  We should show a picture of the overall software organization. I can make this in TikZ following my drawing.

\subsection{Application}

The application code will be written in Python. All development will initially take place here. After profiling, we
will determine which portions must be moved to lower level languages. Of course, we will not put access to fine grained
components from Python in the design. We will establish a shared repository on the
\href{http://www.bitbucket.org}{BitBucket} hosting site using the \href{http://mercurial.selenic.com}{Mercurial} version
control system.

Python allows us to leverage several key components without sacrificing performace. We have access to
\href{http://www.mcs.anl.gov/petsc}{PETSc} via the \href{http://code.google.com/p/petsc4py}{petsc4py} wrappers, and we
will access \href{http://www.amath.washington.edu/~claw/clawpack.org}{CLAWPACK} through new Python wrappers as
well. Moreover, we will tune compute-intensive kernels to \href{http://www.hpc.kaust.edu.sa/wiki/shaheen/}{Shaheen}'s 
BlueGene/P architecture and port small, compute-intensive kernels to the GPU using
\href{http://mathema.tician.de/software/pycuda}{PyCUDA}.

\subsection{Mesh Management}

Our initial implementation will use the PETSc
\href{http://www.mcs.anl.gov/petsc/petsc-as/snapshots/petsc-current/docs/manualpages/DA/index.html}{DA} object to
organize the data on a parallel Cartesian grid. However, at the same time, we will endeavor to move over to the new
Sieve interface, which will allow us to use its arbitrary dimensional \href{}{CartersianMesh}, as well as \href{}{p4est}
from Carsten Burstudde at UT Austin. The p4est library will allow us to also handle the adaptive refinement in
AMRPACK. Another option would be \href{}{DealII}, however it already uses p4est for parallel adaptive structured grids.

\section{Benchmark Problems}

We would like to assemble
\begin{itemize}
  \item 1D advection

  \item 2D metamaterials

  \item 3D elastodynamics
\end{itemize}
benchmarks in order to test our implementation.

\section{People}
\begin{itemize}
  \item[DK] David Ketcheson david.ketcheson@kaust.edu.sa
  \item[GT] George Turkiyyah George.Turkiyyah@kaust.edu.sa
  \item[AA] Aron Ahmadia aron.ahmadia@kaust.edu.sa
  \item[MK] Matt Knepley knepley@gmail.com
  \item[KM] Kyle Mandli mandli@amath.washington.edu 
  \item[AG] Amal Ghamdi amal.ghamdi@kaust.edu.sa
\end{itemize}

\section{Assignments}

\begin{itemize}
  \item[MK] Mercurial Repository on Bitbucket - DONE

  \item[MK] Start application (just update every vertex/cell, maybe do Euler)

  \begin{itemize}
    \item[DK] Add 1D advection and 2D metamaterials

    \item[GT] Add 3D elastodynamics
  \end{itemize}

  \item[MK] Install petsc4py and develop documentation - AA
    responsible for determining locations to install and strategy

  \item[MK] Draw picture of optimization stairstep
  \begin{itemize}
    \item (Python $\to$ C (Cython, Psycho) $\to$ PyCUDA (CodeGen, Templating, FEniCS))
  \end{itemize}

  \item[GT] Introduce CUDA kernels for example problems
  \begin{itemize}
    \item[GT,MK] Start system for generating CUDA kernel from
      specification

    \item[GT,MK] Develop performance models of kernels
  \end{itemize}

  \item[MK,GT] Task Queueing for GPU

  \item[DK,AA] PETSc integration into CLAWPACK

  \item[AA] Investigate Shaheen and Noor cluster scaling of examples
\end{itemize}

\end{document}
